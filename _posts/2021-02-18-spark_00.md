---
title: "Learning Spark"
excerpt: "spark 관련 공부내용 시작"

categories:
  - Spark
tags:
  - Spark
last_modified_at: 2021-02-18
---


![](https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99DF803359B3ECB00D)

스파크 = 클러스터용 연산 플랫폼

- 맵리듀스 모델을 대화형 명령어 쿼리나 스트리밍 처리 등이 가능하도록 확장

### Spark Component

![](https://cdn-images-1.medium.com/max/800/1*UfSqtksZQ_vgrrQtK5DPRA.png)

#### Spark Core

- 작업 스케쥴링, 메모리 관리, 장애 복구, 저장 장치와의 연동 등으로 구성.

- 분산 데이터 세트(RDD)를 정의하는 API의 기반

#### Spark SQL

- 정형 데이터를 처리하기 위한 패키지

- SQL 뿐 아니라 하이브, Parquet, Json 등 다양한 데이터 지원

#### Spark Streaming

- 실시간 데이터 스트림(순차적으로 들어오는 데이터)을 처리

- 스파크 코어와 동일한 수준의 장애관리, 처리량, 확장성 지원

#### MLlib

- 분류, 회귀, 클러스터링, 협업 필터링 등 다양한 타입의 머신 러닝 알고리즘 지원

- 경사하강법, 최적화 등 저수준 ML 핵심 기능 지원

#### GraphX

- 그래프 병렬 연산 수행

- 페이지 랭크, 상각형 세기 등 그래프를 다루는 메소드들 제공

#### Cluster manager

- 하둡의 얀(YARN), 아파치 메소스(Apache Mesos), 독자적인 클러스터 매니저인 단독 스케쥴러(Standalone Scheduler)등 다양한 클러스터 매니저 존재

#### Storage

- 하둡 분산 파일 시스템(HDFS)나 하둡 API가 지원하는 다른 저장 시스템(로컬 파일 시스템, S3, 카산드라 등)에 있는 어떤 파일로부터든 분산 데이터 모음을 생성할 수 있다.

- 텍스트, 시퀸스, 에이브로(Avro), Parquet 뿐 아니라 다른 하둡의 InputFormat이 지원하는 파일까지 지원